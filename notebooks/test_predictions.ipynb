{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ROOT_DIR = \"/home/ebr/projects/inundation-emulator\"\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.emulator import Emulator, DataReader\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained emulator.\n",
    "\n",
    "GENERATED_DIR = \"/home/ebr/projects/inundation-emulator/generated\"\n",
    "TOPO_FILE = '/home/ebr/data/PTHA2020_runs_UMA/Catania/C_CT.grd'\n",
    "TOPO_MASK = '/home/ebr/data/PTHA2020_runs_UMA/Catania/ct_mask.txt'\n",
    "TRAIN_SCENARIOS =\"/home/ebr/data/PTHA2020_runs_UMA/train_591/scenarios.txt\"\n",
    "TRAIN_DIR = '/home/ebr/data/PTHA2020_runs_UMA/train_591'\n",
    "VALIDATION_SCENARIOS = '/home/ebr/data/PTHA2020_runs_UMA/test/scenarios.txt'\n",
    "VALIDATION_DIR = \"/home/ebr/data/PTHA2020_runs_UMA/test\"\n",
    "\n",
    "RUNDIR = \"/home/ebr/projects/inundation-emulator/generated/emulator_20250211_121156\"\n",
    "EPOCH_CHECKPOINT = 500\n",
    "\n",
    "emulator = Emulator(GENERATED_DIR, RUNDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulator.topomask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(emulator.topomask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Create output folder\n",
    "predictions_dir = os.path.join(emulator.rundir, \"predictions\")\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_dir = os.path.join(predictions_dir, emulator.id, f\"preds_{timestamp}\")\n",
    "#os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "emulator.predict(\n",
    "    scenarios_file=TRAIN_SCENARIOS,\n",
    "    input_dir=TRAIN_DIR,\n",
    "    output_dir=output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "scenarios_file = TRAIN_SCENARIOS\n",
    "input_dir = TRAIN_DIR\n",
    "predictions_dir = \"/home/ebr/projects/inundation-emulator/generated/emulator_20250211_121156/predictions\"\n",
    "batch_size = 10\n",
    "\n",
    "# Create output folder\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_dir = os.path.join(predictions_dir, emulator.id, f\"preds_{timestamp}\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(scenarios_file, 'r') as file:\n",
    "    nr_of_scenarios = sum(1 for line in file if line.strip())\n",
    "    print(f\"Number of scenarios for prediction: {nr_of_scenarios}\")\n",
    "\n",
    "reader = DataReader(\n",
    "        rundir=emulator.rundir, \n",
    "        scenarios_file=scenarios_file,\n",
    "        datadir=input_dir,\n",
    "        pois=emulator.pois,\n",
    "        shuffle_on_load=False,\n",
    "        target=True,\n",
    "        reload=False\n",
    ")\n",
    "\n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(emulator.n_pois, emulator.input_time_steps), dtype=tf.float32),           # eta\n",
    "    tf.TensorSpec(shape=(reader.topomask.sum()), dtype=tf.float32),         # No flow_depth\n",
    "    tf.TensorSpec(shape=(), dtype=tf.string)                               # scenario\n",
    ")\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "        generator=reader.generator,\n",
    "        output_signature=output_signature\n",
    ").batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds = np.zeros((batch_size, *reader.topomask.shape))\n",
    "flow_depths = np.zeros((batch_size, *reader.topomask.shape))\n",
    "\n",
    "for eta, flow_depth, scenario_id in dataset:\n",
    "    # Make predictions\n",
    "    #preds[:, topomask] = emulator.model(eta, training=False)\n",
    "    preds[:, emulator.topomask] = emulator.model.predict(eta)\n",
    "    flow_depths[:,emulator.topomask] = flow_depth\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.flip(flow_depths[1,:], axis=0))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.flip(preds[1,:], axis=0))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario, pred in zip(scenario_id, preds):\n",
    "    print(scenario.numpy().decode('utf-8'))\n",
    "    print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import json\n",
    "# Load the stored grid information\n",
    "with open(emulator.grid_info_file, \"r\") as f:\n",
    "    grid_info = json.load(f)\n",
    "\n",
    "for i in range(10):\n",
    "    # Create a NetCDF file for each scenario\n",
    "    scenario_id_str = scenario_id[i].numpy().decode('utf-8')  # Decode scenario_id to string\n",
    "    prediction_data = preds[i,:]\n",
    "    pred_file = os.path.join(output_dir, f\"{scenario_id_str}_CT_10m_PR.nc\")\n",
    "    \n",
    "    with Dataset(pred_file, mode='w', format=\"NETCDF4\") as dst:\n",
    "         # Create dimensions\n",
    "        for dim_name, dim_size in grid_info[\"dimensions\"].items():\n",
    "            dst.createDimension(dim_name, dim_size)\n",
    "\n",
    "        # Create and populate grid variables\n",
    "        for var_name, var_info in grid_info[\"variables\"].items():\n",
    "            dst_var = dst.createVariable(var_name, np.dtype(var_info[\"datatype\"]), var_info[\"dimensions\"])\n",
    "\n",
    "            # Copy attributes\n",
    "            for attr, value in var_info[\"attributes\"].items():\n",
    "                dst_var.setncattr(attr, value)\n",
    "\n",
    "            # Copy data\n",
    "            dst_var[:] = np.array(var_info[\"data\"])\n",
    "        \n",
    "        # Add predicted\n",
    "        prediction = dst.createVariable(\"predicted\", \"f4\", (\"grid_lat\", \"grid_lon\"))\n",
    "        prediction.units = \"meter\"\n",
    "        prediction.description = \"Maximum flow depth.\"\n",
    "        prediction[:,:] = prediction_data\n",
    "        \n",
    "    print(f\"New NetCDF file created: {pred_file}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def inspect_nc_file(file_path):\n",
    "    # Open the NetCDF file\n",
    "    dataset = Dataset(file_path, 'r')\n",
    "    \n",
    "    # Print general information about the dataset\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(f\"Dimensions:\")\n",
    "    pprint(dataset.dimensions)\n",
    "    \n",
    "    print(f\"\\nVariables:\")\n",
    "    pprint(dataset.variables)\n",
    "    \n",
    "    print(f\"\\nGlobal Attributes:\")\n",
    "    pprint(dataset.ncattrs())\n",
    "    for attr in dataset.ncattrs():\n",
    "        print(f\"{attr}: {getattr(dataset, attr)}\")\n",
    "    \n",
    "    # Close the dataset\n",
    "    dataset.close()\n",
    "\n",
    "# Example usage\n",
    "#file_path = '/home/ebr/data/PTHA2020_runs_UMA/train_164/1357_E02020N3739E02658N3366-PS-Mur_PYes_Var-M895_E02426N3465_S002_CT_10m.nc'\n",
    "file_path = '/home/ebr/projects/inundation-emulator/generated/emulator_20250211_121156/predictions/emulator_20250211_121156/preds_20250211_131543/0192_E01548N3896E01854N3659-PS-Str_PYes_Var-M861_E01756N3795_S004_CT_10m_PR.nc'\n",
    "#file_path = '/home/ebr/data/PTHA2020_runs_UMA/train_164/1357_E02020N3739E02658N3366-PS-Mur_PYes_Var-M895_E02426N3465_S002_ts.nc'\n",
    "#file_path = \"/home/ebr/data/PTHA2020_runs_UMA/Catania/C_CT.grd\"\n",
    "inspect_nc_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = '/home/ebr/data/PTHA2020_runs_UMA/train_164/1357_E02020N3739E02658N3366-PS-Mur_PYes_Var-M895_E02426N3465_S002_CT_10m.nc'\n",
    "\n",
    "inspect_nc_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Create an xarray DataArray for the prediction\n",
    "    data = xr.DataArray(\n",
    "        preds[i,:],\n",
    "        dims=topomask.shape,\n",
    "        name=\"prediction\",\n",
    "    )\n",
    "\n",
    "    # Add metadata or attributes if necessary\n",
    "    data.attrs[\"scenario\"] = scenario_id_str\n",
    "    data.attrs[\"description\"] = \"Model predictions for scenario.\"\n",
    "    data.attrs[]\n",
    "\n",
    "    # Save to NetCDF\n",
    "    data.to_netcdf(file_path)\n",
    "    print(f\"Saved predictions for scenario '{scenario_id_str}' to {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inundation-emulator-e-rOiPvR-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
